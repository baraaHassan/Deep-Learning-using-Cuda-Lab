{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf-Sgm27_BoO"
      },
      "source": [
        "## Assignment 6\n",
        "* Write a Variational Convolutional AutoEncoder on CFAR10 + Add denoising to the model\n",
        "* Use the latent space for CFAR10 classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2vwgxKMOMOo"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils as utils\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLV-FDn9ObO4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5bcabcd3-43c1-4e7f-b3cb-9716d8d09a70"
      },
      "source": [
        "# Set Hyperparameters\n",
        "\n",
        "epoch = 10\n",
        "batch_size =100\n",
        "learning_rate = 0.0005\n",
        "\n",
        "# Normalize training data (zero mean and variance of 1)\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "testset = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcs6jyeOOsPI"
      },
      "source": [
        "# Encoder \n",
        "# torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "#                 stride=1, padding=0, dilation=1,\n",
        "#                 groups=1, bias=True)\n",
        "# batch x 1 x 28 x 28 -> batch x 512\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        # input_channel = 1 -> gray scale!\n",
        "                        # output_channel = number of filters!\n",
        "                        nn.Conv2d(3,32,3,padding=1),   # batch x 16 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1),   # batch x 16 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,64,3,padding=1),  # batch x 32 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64,64,3,padding=1),  # batch x 32 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.MaxPool2d(2,2)   # batch x 64 x 14 x 14\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(64,128,3,padding=1),  # batch x 64 x 14 x 14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Conv2d(128,128,3,padding=1),  # batch x 64 x 14 x 14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.MaxPool2d(2,2),\n",
        "                        nn.Conv2d(128,3,3,padding=1),  # batch x 64 x 7 x 7\n",
        "                        nn.ReLU()\n",
        "        )\n",
        "        \n",
        "                \n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        #out = out.view(batch_size, -1)\n",
        "        return out\n",
        "    \n",
        "encoder = Encoder().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRfUwbj-m7zM"
      },
      "source": [
        "inputSize = 3\n",
        "outputSize = 3\n",
        "\n",
        "class HiddenLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HiddenLayer, self).__init__()\n",
        "         \n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=inputSize, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.norm1 = nn.BatchNorm2d(512)\n",
        "\n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.norm2 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        # Fully connected 1 (readout)\n",
        "        self.fc1 = nn.Linear(512 * 8 * 8, outputSize*8*8) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x =  torch.Size([100, 1, 28, 28])\n",
        "        # Convolution 1\n",
        "        out = self.cnn1(x) #torch.Size([100, 16, 24, 24])\n",
        "        out = self.relu1(out) #torch.Size([100, 16, 24, 24])\n",
        "        out = self.norm1(out)\n",
        "\n",
        "        # Convolution 2 \n",
        "        out = self.cnn2(out) #torch.Size([100, 32, 8, 8])\n",
        "        out = self.relu2(out) #torch.Size([100, 32, 8, 8])\n",
        "        out = self.norm2(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1)   #torch.Size([100, 512])\n",
        " \n",
        "        # Linear function (readout)\n",
        "        out = self.fc1(out)\n",
        "         \n",
        "        return out\n",
        "\n",
        "latent = HiddenLayer().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITJxra4CO1nD"
      },
      "source": [
        "# Decoder \n",
        "# torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
        "#                          stride=1, padding=0, output_padding=0,\n",
        "#                          groups=1, bias=True)\n",
        "# output_height = (height-1)*stride + kernel_size - 2*padding + output_padding\n",
        "# batch x 512 -> batch x 1 x 28 x 28\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(3,128,3,2,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ConvTranspose2d(128,128,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ConvTranspose2d(128,64,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ConvTranspose2d(64,64,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(64,32,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,32,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,3,3,2,1,1),\n",
        "                        nn.ReLU()\n",
        "        )\n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        return out\n",
        "\n",
        "decoder = Decoder().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1-7JSpaPALc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4d8e098-87e4-425a-e4f3-68b19ef7bf1d"
      },
      "source": [
        "# Check output of autoencoder\n",
        "for image,label in train_loader:\n",
        "    image = image.cuda()\n",
        "    output = encoder(image)\n",
        "    output = latent(output)\n",
        "    output = output.view(batch_size,3,8,8)\n",
        "    output = decoder(output)\n",
        "    print(output.size())\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNpl7ZAAPEf2"
      },
      "source": [
        "# loss func and optimizer\n",
        "# we compute reconstruction after decoder so use Mean Squared Error\n",
        "# In order to use multi parameters with one optimizer,\n",
        "# concat parameters after changing into list\n",
        "\n",
        "parameters = list(encoder.parameters())+ list(latent.parameters()) + list(decoder.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(parameters, lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpE01TU4qiEO"
      },
      "source": [
        "Train Autoencoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4oGqBTxPHsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "53e4f6a5-48ad-4cb3-9323-4eac8369256f"
      },
      "source": [
        "# train encoder and decoder\n",
        "# save and load model\n",
        "if not os.path.exists('./model'):\n",
        "    os.mkdir('./model')\n",
        "try:\n",
        "    encoder, decoder = torch.load('./model/deno_autoencoder3.pkl')\n",
        "    latent.load_state_dict(torch.load('./model/deno_latent_parameters2.pkl'))\n",
        "    print(\"\\n--------model restored--------\\n\")\n",
        "except:\n",
        "    print(\"\\n--------model not restored--------\\n\")\n",
        "    pass\n",
        "\n",
        "for i in range(epoch):\n",
        "    for image,label in train_loader:\n",
        "        image_n = torch.mul(image+0.25, 0.1 * torch.rand(image.shape[0],3,32,32))\n",
        "        image = image.cuda()\n",
        "        image_n = image_n.cuda()\n",
        "        #label = label.float().cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = encoder(image_n)\n",
        "        output = latent(output)\n",
        "        output = output.view(batch_size,3,8,8)\n",
        "        output = decoder(output)\n",
        "        loss = loss_func(output,image)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('epoch [{}/{}], loss:{:.4f}'\n",
        "          .format(i + 1, epoch, loss.item()))\n",
        "        \n",
        "                \n",
        "torch.save([encoder,decoder],'./model/deno_autoencoder3.pkl')\n",
        "torch.save(latent.state_dict(),'./model/deno_latent_parameters2.pkl')\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------model restored--------\n",
            "\n",
            "epoch [1/10], loss:0.0071\n",
            "epoch [2/10], loss:0.0072\n",
            "epoch [3/10], loss:0.0070\n",
            "epoch [4/10], loss:0.0073\n",
            "epoch [5/10], loss:0.0071\n",
            "epoch [6/10], loss:0.0074\n",
            "epoch [7/10], loss:0.0070\n",
            "epoch [8/10], loss:0.0072\n",
            "epoch [9/10], loss:0.0070\n",
            "epoch [10/10], loss:0.0074\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ConvTranspose2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqXI7KfWqnmY"
      },
      "source": [
        "Use latent layer(as transfer learning) for CIFAR-10 Dataset Classifaction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a40OciDEbhLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "6a7f9660-5d98-43af-e470-25ed47027bf2"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "latent2 = HiddenLayer().cuda()\n",
        "\n",
        "latent2.load_state_dict(torch.load('./model/deno_latent_parameters2.pkl'))\n",
        "\n",
        "latent2 = latent2.to(device)\n",
        "\n",
        "latent2.fc1 = nn.Linear(512*32*32, 10).cuda()\n",
        "\n",
        "#latent = latent.to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(latent2.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    latent2.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = latent2(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    latent2.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = latent2(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    print(\"accuracy = \", acc,\"%\"  )\n",
        "\n",
        "count = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoc in range(num_epochs):\n",
        "    train(epoc)\n",
        "    test(epoc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "accuracy =  52.78 %\n",
            "\n",
            "Epoch: 1\n",
            "accuracy =  60.0 %\n",
            "\n",
            "Epoch: 2\n",
            "accuracy =  60.8 %\n",
            "\n",
            "Epoch: 3\n",
            "accuracy =  59.88 %\n",
            "\n",
            "Epoch: 4\n",
            "accuracy =  60.71 %\n",
            "\n",
            "Epoch: 5\n",
            "accuracy =  60.44 %\n",
            "\n",
            "Epoch: 6\n",
            "accuracy =  61.91 %\n",
            "\n",
            "Epoch: 7\n",
            "accuracy =  59.55 %\n",
            "\n",
            "Epoch: 8\n",
            "accuracy =  61.16 %\n",
            "\n",
            "Epoch: 9\n",
            "accuracy =  61.38 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}